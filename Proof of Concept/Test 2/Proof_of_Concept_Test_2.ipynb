{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-of-concept",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'apt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\oisin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpdf2image\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_from_path    \u001b[38;5;66;03m# Convert PDF pages to images\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpytesseract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Output             \u001b[38;5;66;03m# Structured OCR output (dataframes)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files             \u001b[38;5;66;03m# For uploading & downloading files\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m                        \u001b[38;5;66;03m# Dataframes & Excel export\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m                         \u001b[38;5;66;03m# Numerical utilities\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "#                               FINANCIAL OCR \n",
    "#                     *** Proof of Concept Testing ***\n",
    "# ========================================================================\n",
    "#\n",
    "# What this script does:\n",
    "# 1. Lets you UPLOAD a financial PDF.\n",
    "# 2. Converts each PDF page into an image.\n",
    "# 3. Uses Tesseract OCR to extract:\n",
    "#       - Narrative text (directors' report, notes, etc.)\n",
    "#       - Table-like numeric rows (P&L, balance sheet, notes tables).\n",
    "# 4. Builds:\n",
    "#       - A \"Narrative\" table (by sentence).\n",
    "#       - A \"Tables\" table (by line item / year).\n",
    "# 5. Calculates key metrics:\n",
    "#       - Turnover, Profit, Cash, Net assets, etc.\n",
    "# 6. Tries to compute year-on-year % changes (if 2+ years exist).\n",
    "# 7. Prints a clean human-readable SUMMARY in the Colab output.\n",
    "# 8. Builds Turnover & Profit charts over the years (if data exists).\n",
    "# 9. Exports:\n",
    "#       - An Excel file (Narrative, Tables, Summary).\n",
    "#       - A styled PDF report with:\n",
    "#             * Key metrics table\n",
    "#             * Directors' report highlights\n",
    "#             * Notes highlights\n",
    "#             * Charts embedded\n",
    "#             * Sample of extracted table rows\n",
    "#\n",
    "# Requirements:\n",
    "#   - Run in Google Colab.\n",
    "#   - Upload a Financial PDF.\n",
    "#\n",
    "# ========================================================================\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 1 â€” INSTALL SYSTEM & PYTHON DEPENDENCIES (COLAB-SPECIFIC)\n",
    "# ------------------------------------------------------------------------\n",
    "# These shell commands (starting with \"!\") are specific to Colab / Jupyter.\n",
    "# They install system packages and Python libraries needed for the pipeline.\n",
    "\n",
    "!apt update -qq\n",
    "!apt install -y -qq tesseract-ocr poppler-utils\n",
    "!pip install -q pytesseract pdf2image regex nltk openpyxl reportlab matplotlib\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 2 â€” IMPORT PYTHON LIBRARIES\n",
    "# ------------------------------------------------------------------------\n",
    "# Now import all the Python modules weâ€™ll use.\n",
    "\n",
    "import pytesseract                         # Python wrapper around Tesseract OCR\n",
    "from pdf2image import convert_from_path    # Convert PDF pages to images\n",
    "from pytesseract import Output             # Structured OCR output (dataframes)\n",
    "\n",
    "from google.colab import files             # For uploading & downloading files\n",
    "\n",
    "import pandas as pd                        # Dataframes & Excel export\n",
    "import numpy as np                         # Numerical utilities\n",
    "import regex as re                         # Advanced regular expressions\n",
    "\n",
    "import nltk                                # Natural Language Toolkit\n",
    "from nltk.tokenize import sent_tokenize    # Sentence splitting\n",
    "\n",
    "import matplotlib.pyplot as plt            # Charts & graphs\n",
    "from io import BytesIO                     # In-memory binary streams (for charts)\n",
    "\n",
    "# ReportLab for building a PDF report\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import (\n",
    "    SimpleDocTemplate, Paragraph, Spacer,\n",
    "    Table as RLTable, TableStyle,\n",
    "    Image as RLImage, PageBreak\n",
    ")\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "# Download NLTK sentence tokenizer data once in the Colab environment\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 3 â€” HELPER REGEX PATTERNS & EXTRACTION FUNCTIONS\n",
    "# ------------------------------------------------------------------------\n",
    "# These are small utilities that will be reuse throughout the script to\n",
    "# extract numbers, years, dates, names, etc.\n",
    "\n",
    "\n",
    "# Pattern to match money-like tokens, e.g.:\n",
    "#   \"â‚¬10,000\", \"Â£500\", \"1,250,300\", \"(35,000)\"\n",
    "_money_re = re.compile(r\"(?:â‚¬|Â£)?\\s*[-(]?\\d[\\d,\\,\\.]*\\)?\")\n",
    "\n",
    "# Pattern to match years such as 2019, 2020, 2023\n",
    "_year_re = re.compile(r\"\\b(20\\d{2})\\b\")\n",
    "\n",
    "# Pattern to match long-form dates (e.g. \"12 March 2024\")\n",
    "_date_re = re.compile(\n",
    "    r\"\\b\\d{1,2}\\s+\"\n",
    "    r\"(January|February|March|April|May|June|July|August|September|October|November|December)\"\n",
    "    r\"\\s+\\d{4}\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Pattern to detect simple personal names (first + optional middle + last)\n",
    "_name_re = re.compile(r\"\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+){0,2}\\b\")\n",
    "\n",
    "\n",
    "def extract_financial_numbers(text):\n",
    "    \"\"\"\n",
    "    Extracts all values that look like monetary or numeric amounts from a line of text.\n",
    "\n",
    "    Example:\n",
    "        \"Turnover 4,863,792 3,965,645\"\n",
    "    might yield:\n",
    "        [(\"4,863,792\", 4863792.0), (\"3,965,645\", 3965645.0)]\n",
    "\n",
    "    Also handles parentheses for negatives:\n",
    "        \"(35,000)\" -> -35000.0\n",
    "    \"\"\"\n",
    "    numbers = []\n",
    "\n",
    "    for m in re.finditer(_money_re, text):\n",
    "        original = m.group(0)\n",
    "\n",
    "        # Convert \"(1000)\" to \"-1000\"\n",
    "        cleaned = original.replace(\"(\", \"-\").replace(\")\", \"\")\n",
    "\n",
    "        # Keep only digits, decimal points, and minus sign\n",
    "        numeric = re.sub(r\"[^\\d\\.\\-]\", \"\", cleaned)\n",
    "\n",
    "        # Filter out nonsense like \"\" or just \"-\"\n",
    "        if numeric in (\"\", \"-\", \".\", \"-.\"):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            num = float(numeric.replace(\",\", \"\"))\n",
    "            numbers.append((original.strip(), num))\n",
    "        except:\n",
    "            # If conversion fails, ignore this match\n",
    "            pass\n",
    "\n",
    "    return numbers\n",
    "\n",
    "\n",
    "def extract_years(text):\n",
    "    \"\"\"Return a list of all years like 2020, 2021 found in text.\"\"\"\n",
    "    return _year_re.findall(text)\n",
    "\n",
    "\n",
    "def extract_dates(text):\n",
    "    \"\"\"Return a list of long-form dates (day + month + year).\"\"\"\n",
    "    return _date_re.findall(text)\n",
    "\n",
    "\n",
    "def extract_names(text):\n",
    "    \"\"\"\n",
    "    Roughly extract names of people from text, excluding obvious false positives\n",
    "    like 'Company', 'Limited', 'Page', etc.\n",
    "    \"\"\"\n",
    "    names = _name_re.findall(text)\n",
    "    return [n for n in names if n.lower() not in (\"company\", \"limited\", \"notes\", \"page\")]\n",
    "\n",
    "\n",
    "def sanitize_label(label):\n",
    "    \"\"\"Normalize whitespace in labels, removing extra spaces.\"\"\"\n",
    "    return re.sub(r\"\\s+\", \" \", label).strip()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# SECTION CLASSIFIER â€” to categorise narrative sentences\n",
    "# ------------------------------------------------------------------------\n",
    "# Want to mark each sentence as belonging to:\n",
    "#   - directors_report\n",
    "#   - results\n",
    "#   - assets\n",
    "#   - liabilities\n",
    "#   - equity\n",
    "#   - notes\n",
    "#   - accounting_records\n",
    "#   - general\n",
    "#\n",
    "# This helps build a structured summary later (e.g., \"Directors' Report Highlights\").\n",
    "\n",
    "SECTION_KEYWORDS = {\n",
    "    \"directors_report\": [\n",
    "        \"director\", \"director's report\", \"directors report\", \"board\"\n",
    "    ],\n",
    "    \"results\": [\n",
    "        \"profit\", \"loss\", \"turnover\", \"tax\", \"profit for the financial year\"\n",
    "    ],\n",
    "    \"assets\": [\n",
    "        \"assets\", \"tangible\", \"stocks\", \"debtors\", \"inventory\", \"inventories\"\n",
    "    ],\n",
    "    \"liabilities\": [\n",
    "        \"liabilities\", \"creditors\"\n",
    "    ],\n",
    "    \"equity\": [\n",
    "        \"equity\", \"share capital\", \"reserves\"\n",
    "    ],\n",
    "    \"notes\": [\n",
    "        \"notes to the financial statements\", \"notes to\"\n",
    "    ],\n",
    "    \"accounting_records\": [\n",
    "        \"accounting records\"\n",
    "    ],\n",
    "    \"general\": []\n",
    "}\n",
    "\n",
    "\n",
    "def classify_section(text):\n",
    "    \"\"\"\n",
    "    Determine which section a piece of text likely belongs to by checking\n",
    "    for certain keywords. If none match, return 'general'.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    for section, words in SECTION_KEYWORDS.items():\n",
    "        for w in words:\n",
    "            if w in t:\n",
    "                return section\n",
    "    return \"general\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# UPLOAD THE PDF (USER INTERACTION)\n",
    "# ------------------------------------------------------------------------\n",
    "# This shows a file chooser in Colab. Must select a financial PDF from\n",
    "# your local computer. The rest of the script uses that PDF for processing.\n",
    "\n",
    "print(\"Please upload your financial document (PDF):\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    raise SystemExit(\"No file uploaded. Please run the cell again and upload a PDF.\")\n",
    "\n",
    "pdf_path = list(uploaded.keys())[0]\n",
    "print(\"Using file:\", pdf_path)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 4 â€” CONVERT PDF PAGES TO IMAGES\n",
    "# ------------------------------------------------------------------------\n",
    "# Tesseract OCR cannot read PDFs directly; it works on images.\n",
    "# pdf2image.convert_from_path() creates an image (PIL Image) for each page.\n",
    "\n",
    "print(\"\\nConverting PDF pages to images (300 DPI)...\")\n",
    "pages = convert_from_path(pdf_path, dpi=300)\n",
    "print(f\"Conversion complete: {len(pages)} page(s) converted.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 5 â€” OCR EACH PAGE (FULL TEXT + LINE-LEVEL DATA)\n",
    "# ------------------------------------------------------------------------\n",
    "# Perform OCR in two ways:\n",
    "#   1) get full text for narrative analysis\n",
    "#   2) get line-level bounding boxes and text for table-like structure parsing\n",
    "\n",
    "print(\"\\nRunning OCR on all pages...\")\n",
    "\n",
    "page_texts = []         # full text per page (for narrative)\n",
    "all_lines_by_page = []  # line-level OCR with coordinates for each page\n",
    "\n",
    "for page_index, page in enumerate(pages, start=1):\n",
    "    # 1) Full-page text\n",
    "    text = pytesseract.image_to_string(page)\n",
    "    page_texts.append(text)\n",
    "\n",
    "    # 2) Line-level OCR with bounding boxes\n",
    "    df = pytesseract.image_to_data(page, output_type=Output.DATAFRAME)\n",
    "\n",
    "    if 'text' not in df.columns:\n",
    "        # If OCR completely failed on this page\n",
    "        all_lines_by_page.append([])\n",
    "        continue\n",
    "\n",
    "    # Remove rows where 'text' is NaN\n",
    "    df = df.dropna(subset=[\"text\"])\n",
    "\n",
    "    # Group by Tesseract's (block, paragraph, line) IDs to get one row per line\n",
    "    grouped = df.groupby([\"block_num\", \"par_num\", \"line_num\"])\n",
    "    lines = []\n",
    "\n",
    "    for _, g in grouped:\n",
    "        line_text = \" \".join(g[\"text\"].astype(str).tolist()).strip()\n",
    "        if not line_text:\n",
    "            continue\n",
    "\n",
    "        left = int(g[\"left\"].min())\n",
    "        top = int(g[\"top\"].min())\n",
    "        right = int((g[\"left\"] + g[\"width\"]).max())\n",
    "        width = right - left\n",
    "        height = int((g[\"top\"] + g[\"height\"]).max() - top)\n",
    "\n",
    "        lines.append((line_text, left, top, width, height))\n",
    "\n",
    "    # Sort lines by vertical position then left-right, to approximate reading order\n",
    "    lines = sorted(lines, key=lambda x: (x[2], x[1]))\n",
    "\n",
    "    # Basic label-value merge:\n",
    "    # If a line has no numbers but the next one does, merge them so we get\n",
    "    # \"Label  123,456  234,567\" instead of \"Label\" and then numbers on the next line.\n",
    "    merged_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        text_line, l, t, w, h = lines[i]\n",
    "        nums = extract_financial_numbers(text_line)\n",
    "\n",
    "        if len(nums) == 0 and i + 1 < len(lines):\n",
    "            nxt_text, nl, nt, nw, nh = lines[i + 1]\n",
    "            if extract_financial_numbers(nxt_text):\n",
    "                merged_lines.append((\n",
    "                    f\"{text_line} {nxt_text}\",\n",
    "                    min(l, nl),\n",
    "                    min(t, nt),\n",
    "                    max(w, nw),\n",
    "                    max(h, nh)\n",
    "                ))\n",
    "                i += 2\n",
    "                continue\n",
    "\n",
    "        merged_lines.append((text_line, l, t, w, h))\n",
    "        i += 1\n",
    "\n",
    "    all_lines_by_page.append(merged_lines)\n",
    "\n",
    "print(\"OCR complete. Collected full text and line-level data.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 6 â€” NARRATIVE SENTENCE EXTRACTION\n",
    "# ------------------------------------------------------------------------\n",
    "# Work with the full text (all pages combined). We'll:\n",
    "#   1) Split it into sentences with NLTK.\n",
    "#   2) For each sentence:\n",
    "#        * detect which section it's from\n",
    "#        * extract numeric values (current year, prior year where possible)\n",
    "#        * extract names and dates\n",
    "#   3) Store everything in a DataFrame df_narrative.\n",
    "\n",
    "print(\"\\nExtracting narrative sentences from OCR text...\")\n",
    "\n",
    "full_text = \"\\n\".join(page_texts)\n",
    "sentences = sent_tokenize(full_text)\n",
    "\n",
    "narrative_rows = []\n",
    "\n",
    "for s in sentences:\n",
    "    s_clean = s.replace(\"\\x0c\", \" \").strip()  # remove strange page-break characters\n",
    "    if not s_clean:\n",
    "        continue\n",
    "\n",
    "    section = classify_section(s_clean)\n",
    "    nums = extract_financial_numbers(s_clean)\n",
    "\n",
    "    current_val = nums[0][1] if len(nums) > 0 else \"\"\n",
    "    prior_val   = nums[1][1] if len(nums) > 1 else \"\"\n",
    "\n",
    "    narrative_rows.append({\n",
    "        \"section\":       section,\n",
    "        \"text\":          s_clean,\n",
    "        \"value_current\": current_val,\n",
    "        \"value_prior\":   prior_val,\n",
    "        \"names\":         \", \".join(extract_names(s_clean)),\n",
    "        \"dates\":         \", \".join(extract_dates(s_clean))\n",
    "    })\n",
    "\n",
    "df_narrative = pd.DataFrame(narrative_rows)\n",
    "print(f\"Narrative sentences extracted: {len(df_narrative)} rows.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 7 â€” TABLE-LIKE STRUCTURE PARSING FROM LINE-LEVEL OCR\n",
    "# ------------------------------------------------------------------------\n",
    "# We want to interpret groups of numeric lines as potential tables. We:\n",
    "#   1) Discover blocks of consecutive numeric lines.\n",
    "#   2) Try to find year headers (e.g. \"2024 2023\") above or in the block.\n",
    "#   3) For each line:\n",
    "#         * determine the label\n",
    "#         * assign numbers to year columns (year_2024, year_2023, ...)\n",
    "#   4) Store results in df_tables.\n",
    "\n",
    "print(\"\\nParsing table-like blocks into structured rows...\")\n",
    "\n",
    "table_entries = []\n",
    "\n",
    "for page_index, lines in enumerate(all_lines_by_page, start=1):\n",
    "    if not lines:\n",
    "        continue\n",
    "\n",
    "    # Flag lines containing numeric tokens\n",
    "    numeric_flag = [1 if extract_financial_numbers(l[0]) else 0 for l in lines]\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if numeric_flag[i] == 1:\n",
    "            # Start of a numeric block\n",
    "            start = i\n",
    "            j = i + 1\n",
    "\n",
    "            # Extend the block while lines are numeric or very close vertically\n",
    "            while j < len(lines) and (numeric_flag[j] == 1 or j - start < 6):\n",
    "                j += 1\n",
    "\n",
    "            block = lines[start:j]\n",
    "\n",
    "            # If no numeric lines in block, skip (safety check)\n",
    "            if sum(numeric_flag[start:j]) < 1:\n",
    "                i = j\n",
    "                continue\n",
    "\n",
    "            # Try to detect header years in top lines of block\n",
    "            header_text = \"\"\n",
    "            header_years = []\n",
    "\n",
    "            for cand in block[:3]:\n",
    "                yrs = extract_years(cand[0])\n",
    "                if yrs:\n",
    "                    header_text = cand[0]\n",
    "                    header_years = yrs\n",
    "                    break\n",
    "\n",
    "            # If not found, look above the block in previous lines on same page\n",
    "            if not header_years and start - 1 >= 0:\n",
    "                for k in range(max(0, start - 2), start):\n",
    "                    yrs = extract_years(lines[k][0])\n",
    "                    if yrs:\n",
    "                        header_text = lines[k][0]\n",
    "                        header_years = yrs\n",
    "                        break\n",
    "\n",
    "            # Process each row in the block\n",
    "            for row_text, left, top, width, height in block:\n",
    "                raw = row_text.strip()\n",
    "                nums = [v for _, v in extract_financial_numbers(raw)]\n",
    "\n",
    "                # Find where the first money-like token occurs to split label/value\n",
    "                first_money = None\n",
    "                for m in re.finditer(_money_re, raw):\n",
    "                    first_money = m\n",
    "                    break\n",
    "\n",
    "                if first_money:\n",
    "                    label = raw[:first_money.start()].strip(\" -:;,\")\n",
    "                else:\n",
    "                    # Fallback: take first chunk before big gap\n",
    "                    label = re.split(r\"\\s{2,}\", raw)[0].strip()\n",
    "\n",
    "                entry = {\n",
    "                    \"page\":      page_index,\n",
    "                    \"section\":   classify_section(header_text if header_text else label),\n",
    "                    \"line_item\": sanitize_label(label),\n",
    "                    \"names\":     \", \".join(extract_names(raw)),\n",
    "                    \"dates\":     \", \".join(extract_dates(raw)),\n",
    "                }\n",
    "\n",
    "                # If we have header years, map numbers to those exact years\n",
    "                if header_years:\n",
    "                    for idx_y, y in enumerate(header_years):\n",
    "                        entry[f\"year_{y}\"] = nums[idx_y] if idx_y < len(nums) else \"\"\n",
    "\n",
    "                    # 'current' = latest year, 'prior' = previous year if available\n",
    "                    sorted_years = sorted(header_years, reverse=True)\n",
    "                    entry[\"value_current\"] = entry.get(f\"year_{sorted_years[0]}\", \"\")\n",
    "                    entry[\"value_prior\"]   = entry.get(f\"year_{sorted_years[1]}\", \"\") if len(sorted_years) > 1 else \"\"\n",
    "                else:\n",
    "                    # No explicit year headers; just assign sequentially\n",
    "                    for idx_n, val in enumerate(nums):\n",
    "                        entry[f\"year_{idx_n+1}\"] = val\n",
    "                    entry[\"value_current\"] = nums[0] if len(nums) > 0 else \"\"\n",
    "                    entry[\"value_prior\"]   = nums[1] if len(nums) > 1 else \"\"\n",
    "\n",
    "                table_entries.append(entry)\n",
    "\n",
    "            i = j  # skip to end of this block\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "df_tables = pd.DataFrame(table_entries).fillna(\"\")\n",
    "\n",
    "# Deduplicate rows by (section, line_item), because OCR can sometimes\n",
    "# produce duplicate lines.\n",
    "if not df_tables.empty:\n",
    "    df_tables[\"line_item\"] = (\n",
    "        df_tables[\"line_item\"]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "    seen_keys = set()\n",
    "    unique_rows = []\n",
    "    for _, row in df_tables.iterrows():\n",
    "        key = (row.get(\"section\", \"\"), row.get(\"line_item\", \"\"))\n",
    "        if key in seen_keys:\n",
    "            continue\n",
    "        seen_keys.add(key)\n",
    "        unique_rows.append(row.to_dict())\n",
    "\n",
    "    df_tables = pd.DataFrame(unique_rows)\n",
    "\n",
    "print(f\"Structured table rows detected: {len(df_tables)}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 8 â€” METRIC EXTRACTION & YEAR-ON-YEAR (YOY) ANALYSIS\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\nComputing key metrics and year-on-year comparisons...\\n\")\n",
    "\n",
    "\n",
    "def find_metric(keywords):\n",
    "    \"\"\"\n",
    "    Try to extract a financial metric by searching for one or more\n",
    "    keywords in:\n",
    "      1) df_tables[\"line_item\"] first (structured)\n",
    "      2) df_narrative[\"text\"] if not found in tables\n",
    "\n",
    "    Returns:\n",
    "      A numeric value (float-like) or \"\" if nothing found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Search structured table rows first\n",
    "    for kw in keywords:\n",
    "        mask = df_tables[\"line_item\"].str.lower().str.contains(kw, na=False)\n",
    "        if mask.any():\n",
    "            row = df_tables[mask].iloc[0]\n",
    "\n",
    "            # Prefer the highest year_XXXX column if present\n",
    "            year_cols = sorted(\n",
    "                [c for c in row.keys() if c.startswith(\"year_\")],\n",
    "                reverse=True\n",
    "            )\n",
    "            if year_cols:\n",
    "                return row[year_cols[0]]\n",
    "\n",
    "            return row.get(\"value_current\", \"\")\n",
    "\n",
    "    # Fallback to narrative sentences\n",
    "    for kw in keywords:\n",
    "        mask = df_narrative[\"text\"].str.lower().str.contains(kw, na=False)\n",
    "        if mask.any():\n",
    "            row = df_narrative[mask].iloc[0]\n",
    "            if row[\"value_current\"]:\n",
    "                return row[\"value_current\"]\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# Build dictionary of metrics with human-readable keys\n",
    "metrics = {}\n",
    "metrics[\"Turnover\"]              = find_metric([\"turnover\", \"sales\"])\n",
    "metrics[\"Profit for the year\"]   = find_metric([\"profit for the financial year\", \"profit for the year\", \"profit\"])\n",
    "metrics[\"Tax\"]                   = find_metric([\"tax on profit\", \"corporation tax\", \"tax\"])\n",
    "metrics[\"Tangible assets\"]       = find_metric([\"tangible assets\", \"tangible\"])\n",
    "metrics[\"Stocks\"]                = find_metric([\"stocks\", \"inventories\"])\n",
    "metrics[\"Debtors\"]               = find_metric([\"debtors\", \"trade debtors\"])\n",
    "metrics[\"Cash\"]                  = find_metric([\"cash at bank\", \"cash at bank and in hand\", \"cash\"])\n",
    "metrics[\"Creditors <1 year\"]     = find_metric([\"falling due within one year\", \"within one year\"])\n",
    "metrics[\"Creditors >1 year\"]     = find_metric([\"falling due after more than one year\", \"after more than\"])\n",
    "metrics[\"Net current assets\"]    = find_metric([\"net current assets\"])\n",
    "metrics[\"Total assets less current liabs\"] = find_metric([\"total assets less current liabilities\"])\n",
    "metrics[\"Net assets\"]            = find_metric([\"net assets\"])\n",
    "metrics[\"Share capital\"]         = find_metric([\"called up share capital\", \"share capital\"])\n",
    "\n",
    "\n",
    "# Extract employees from narrative text (if mentioned)\n",
    "employees = \"\"\n",
    "for txt in df_narrative[\"text\"]:\n",
    "    m = re.search(r\"employees?.{0,30}?(\\d{1,4})\", txt, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        employees = m.group(1)\n",
    "        break\n",
    "\n",
    "\n",
    "# ------------------ YOY (Year-on-Year) Summary ------------------\n",
    "\n",
    "yoy_summary = {}   # metric_name -> % change\n",
    "\n",
    "# Identify all year_* columns present in df_tables\n",
    "all_year_cols = sorted({col for col in df_tables.columns if col.startswith(\"year_\")})\n",
    "years = [col.replace(\"year_\", \"\") for col in all_year_cols]\n",
    "\n",
    "if len(years) >= 2:\n",
    "    years = sorted(years)  # ascending order\n",
    "    latest_year = years[-1]\n",
    "    prev_year   = years[-2]\n",
    "\n",
    "    for metric_name, val_current in metrics.items():\n",
    "\n",
    "        # Only attempt YOY for metrics that exist numerically\n",
    "        if val_current in (\"\", None):\n",
    "            continue\n",
    "\n",
    "        # We attempt to re-locate the metric row for older year data\n",
    "        if metric_name == \"Turnover\":\n",
    "            keywords = [\"turnover\", \"sales\"]\n",
    "        elif metric_name == \"Profit for the year\":\n",
    "            keywords = [\"profit for the financial year\", \"profit for the year\", \"profit\"]\n",
    "        else:\n",
    "            keywords = [metric_name.lower()]\n",
    "\n",
    "        older_val = None\n",
    "\n",
    "        for kw in keywords:\n",
    "            mask = df_tables[\"line_item\"].str.lower().str.contains(kw, na=False)\n",
    "            if mask.any():\n",
    "                row = df_tables[mask].iloc[0]\n",
    "                older_col = f\"year_{prev_year}\"\n",
    "                if older_col in row and row[older_col] not in (\"\", None):\n",
    "                    older_val = row[older_col]\n",
    "                break\n",
    "\n",
    "        try:\n",
    "            if older_val not in (\"\", None):\n",
    "                v_new = float(val_current)\n",
    "                v_old = float(older_val)\n",
    "                if v_old != 0:\n",
    "                    change_pct = ((v_new - v_old) / v_old) * 100.0\n",
    "                    yoy_summary[metric_name] = round(change_pct, 2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 8B â€” HUMAN-READABLE SUMMARY IN THE COLAB OUTPUT\n",
    "# ------------------------------------------------------------------------\n",
    "# This prints a friendly summary you can read directly in the notebook\n",
    "# without opening Excel or the generated PDF.\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"         SUMMARY\")\n",
    "print(\"======================\\n\")\n",
    "\n",
    "\n",
    "def fmt(value):\n",
    "    \"\"\"Format a numeric value as â‚¬x,xxx or return 'N/A'.\"\"\"\n",
    "    if value in (\"\", None):\n",
    "        return \"N/A\"\n",
    "    try:\n",
    "        return f\"â‚¬{float(value):,.0f}\"\n",
    "    except:\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "# 1. Key metrics\n",
    "print(\"ðŸ”¹ KEY FINANCIAL METRICS:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"   â€¢ {metric:30s}: {fmt(value)}\")\n",
    "\n",
    "print(f\"   â€¢ {'Employees':30s}: {employees if employees else 'N/A'}\")\n",
    "\n",
    "\n",
    "# 2. YOY changes\n",
    "print(\"\\nðŸ”¹ YEAR-ON-YEAR CHANGES (if two years detected):\")\n",
    "if yoy_summary:\n",
    "    for metric, pct in yoy_summary.items():\n",
    "        direction = \"ðŸ“ˆ Increase\" if pct > 0 else \"ðŸ“‰ Decrease\"\n",
    "        print(f\"   â€¢ {metric:30s}: {pct}% ({direction})\")\n",
    "else:\n",
    "    print(\"   Only one year detected or insufficient data for YOY.\")\n",
    "\n",
    "\n",
    "# 3. Directors' report highlights\n",
    "print(\"\\nðŸ”¹ DIRECTORSâ€™ REPORT HIGHLIGHTS:\")\n",
    "directors_highlights = df_narrative[df_narrative[\"section\"] == \"directors_report\"][\"text\"].tolist()\n",
    "if not directors_highlights:\n",
    "    print(\"   No directors' report text detected.\")\n",
    "else:\n",
    "    for point in directors_highlights[:5]:\n",
    "        snippet = point[:250] + (\"...\" if len(point) > 250 else \"\")\n",
    "        print(f\"   â€¢ {snippet}\")\n",
    "\n",
    "\n",
    "# 4. Notes to the accounts\n",
    "print(\"\\nðŸ”¹ NOTES TO THE ACCOUNTS (Key Policies):\")\n",
    "notes_highlights = df_narrative[df_narrative[\"section\"] == \"notes\"][\"text\"].tolist()\n",
    "if not notes_highlights:\n",
    "    print(\"   No notes text detected.\")\n",
    "else:\n",
    "    for point in notes_highlights[:5]:\n",
    "        snippet = point[:250] + (\"...\" if len(point) > 250 else \"\")\n",
    "        print(f\"   â€¢ {snippet}\")\n",
    "\n",
    "\n",
    "# 5. Assets & liabilities overview\n",
    "print(\"\\nðŸ”¹ ASSET & LIABILITY OVERVIEW:\")\n",
    "print(f\"   â€¢ Tangible Assets:            {fmt(metrics.get('Tangible assets'))}\")\n",
    "print(f\"   â€¢ Stocks:                     {fmt(metrics.get('Stocks'))}\")\n",
    "print(f\"   â€¢ Debtors:                    {fmt(metrics.get('Debtors'))}\")\n",
    "print(f\"   â€¢ Cash:                       {fmt(metrics.get('Cash'))}\")\n",
    "print(f\"   â€¢ Creditors <1 Year:          {fmt(metrics.get('Creditors <1 year'))}\")\n",
    "print(f\"   â€¢ Creditors >1 Year:          {fmt(metrics.get('Creditors >1 year'))}\")\n",
    "print(f\"   â€¢ Net Current Assets:         {fmt(metrics.get('Net current assets'))}\")\n",
    "print(f\"   â€¢ Net Assets:                 {fmt(metrics.get('Net assets'))}\")\n",
    "\n",
    "\n",
    "# 6. Summary sentence on performance\n",
    "print(\"\\nðŸ”¹ PERFORMANCE SUMMARY:\")\n",
    "turn = metrics.get(\"Turnover\")\n",
    "prof = metrics.get(\"Profit for the year\")\n",
    "if turn and prof:\n",
    "    print(f\"   The company recorded turnover of {fmt(turn)} and a profit of {fmt(prof)} \"\n",
    "          f\"in the latest financial year.\")\n",
    "else:\n",
    "    print(\"   Turnover and/or profit figures could not be reliably detected.\")\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\" END OF SUMMARY REPORT\")\n",
    "print(\"======================\\n\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 9 â€” BUILD CHARTS (TURNOVER & PROFIT BY YEAR)\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "print(\"Building charts for Turnover and Profit (if data series found)...\")\n",
    "\n",
    "chart_images = []  # will store (title, BytesIO_png_image)\n",
    "\n",
    "\n",
    "def build_series_from_tables(item_keywords):\n",
    "    \"\"\"\n",
    "    For a given set of keywords, try to find a matching line_item in df_tables\n",
    "    and build a year â†’ value dictionary from its year_* columns.\n",
    "\n",
    "    Returns: (years_sorted_list, values_list) or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    for kw in item_keywords:\n",
    "        mask = df_tables[\"line_item\"].str.lower\n",
    "\n",
    "# Continue chart builder function\n",
    "        mask = df_tables[\"line_item\"].str.lower().str.contains(kw, na=False)\n",
    "        if mask.any():\n",
    "            row = df_tables[mask].iloc[0]\n",
    "\n",
    "            # Extract all year columns for this metric\n",
    "            year_data = {}\n",
    "            for col in row.index:\n",
    "                if col.startswith(\"year_\") and row[col] not in (\"\", None):\n",
    "                    year = col.replace(\"year_\", \"\")\n",
    "                    try:\n",
    "                        year_data[year] = float(row[col])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "            if year_data:\n",
    "                years_sorted = sorted(year_data.keys())      # ascending\n",
    "                values_sorted = [year_data[y] for y in years_sorted]\n",
    "                return years_sorted, values_sorted\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# Build Turnover chart\n",
    "turn_years, turn_vals = build_series_from_tables([\"turnover\", \"sales\"])\n",
    "if turn_years:\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.plot(turn_years, turn_vals, marker=\"o\")\n",
    "    ax.set_title(\"Turnover by Year\")\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Turnover (â‚¬)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    chart_images.append((\"Turnover by Year\", buf))\n",
    "\n",
    "\n",
    "# Build Profit chart\n",
    "prof_years, prof_vals = build_series_from_tables([\"profit for the financial year\", \"profit\"])\n",
    "if prof_years:\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.plot(prof_years, prof_vals, marker=\"o\", color=\"green\")\n",
    "    ax.set_title(\"Profit by Year\")\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Profit (â‚¬)\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    chart_images.append((\"Profit by Year\", buf))\n",
    "\n",
    "\n",
    "print(\"Charts built:\", len(chart_images))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 10 â€” EXPORT TO EXCEL\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "excel_name = \"financial_output.xlsx\"\n",
    "with pd.ExcelWriter(excel_name, engine=\"openpyxl\") as writer:\n",
    "    df_narrative.to_excel(writer, sheet_name=\"Narrative\", index=False)\n",
    "    df_tables.to_excel(writer, sheet_name=\"Tables\", index=False)\n",
    "\n",
    "    # Metrics summary sheet\n",
    "    pd.DataFrame(\n",
    "        list(metrics.items()),\n",
    "        columns=[\"Metric\", \"Value\"]\n",
    "    ).to_excel(writer, sheet_name=\"Summary\", index=False)\n",
    "\n",
    "print(\"Excel generated:\", excel_name)\n",
    "files.download(excel_name)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# PART 11 â€” BUILD STYLED PDF REPORT\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "pdf_name = \"Financial_Summary_Report.pdf\"\n",
    "styles = getSampleStyleSheet()\n",
    "styleH = ParagraphStyle(\"Heading\", parent=styles[\"Heading1\"], alignment=1)\n",
    "styleN = styles[\"Normal\"]\n",
    "styleB = ParagraphStyle(\"Bold\", parent=styles[\"Normal\"], fontName=\"Helvetica-Bold\")\n",
    "\n",
    "story = []\n",
    "doc = SimpleDocTemplate(pdf_name, pagesize=A4, rightMargin=36, leftMargin=36, topMargin=36, bottomMargin=36)\n",
    "\n",
    "# Title\n",
    "story.append(Paragraph(\"Financial Summary Report\", styleH))\n",
    "story.append(Paragraph(f\"Source Document: {pdf_path}\", styleN))\n",
    "story.append(Spacer(1, 0.2 * inch))\n",
    "\n",
    "# Metrics table\n",
    "table_data = [[\"Metric\", \"Value\"]]\n",
    "for k, v in metrics.items():\n",
    "    table_data.append([k, fmt(v)])\n",
    "\n",
    "tbl = RLTable(table_data, colWidths=[2.5 * inch, 3.5 * inch])\n",
    "tbl.setStyle(TableStyle([\n",
    "    (\"BACKGROUND\", (0, 0), (-1, 0), colors.lightgrey),\n",
    "    (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
    "    (\"GRID\", (0, 0), (-1, -1), 0.25, colors.black),\n",
    "]))\n",
    "story.append(tbl)\n",
    "story.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "# Directors' highlights\n",
    "story.append(Paragraph(\"Directors' Report Highlights\", styleB))\n",
    "if directors_highlights:\n",
    "    for t in directors_highlights[:5]:\n",
    "        story.append(Paragraph(\"- \" + t[:300] + (\"...\" if len(t) > 300 else \"\"), styleN))\n",
    "else:\n",
    "    story.append(Paragraph(\"No directors' report content detected.\", styleN))\n",
    "\n",
    "story.append(Spacer(1, 0.3 * inch))\n",
    "\n",
    "# Notes highlights\n",
    "story.append(Paragraph(\"Notes to the Accounts (Extracts)\", styleB))\n",
    "if notes_highlights:\n",
    "    for t in notes_highlights[:5]:\n",
    "        story.append(Paragraph(\"- \" + t[:300] + (\"...\" if len(t) > 300 else \"\"), styleN))\n",
    "else:\n",
    "    story.append(Paragraph(\"No notes extracted.\", styleN))\n",
    "\n",
    "story.append(PageBreak())\n",
    "\n",
    "# Charts\n",
    "if chart_images:\n",
    "    story.append(Paragraph(\"Charts\", styleH))\n",
    "    for title, img_buf in chart_images:\n",
    "        story.append(Paragraph(title, styleB))\n",
    "        story.append(RLImage(img_buf, width=6.0 * inch, height=2.5 * inch))\n",
    "        story.append(Spacer(1, 0.3 * inch))\n",
    "else:\n",
    "    story.append(Paragraph(\"No charts available.\", styleN))\n",
    "\n",
    "# Build PDF\n",
    "doc.build(story)\n",
    "print(\"PDF generated:\", pdf_name)\n",
    "files.download(pdf_name)\n",
    "\n",
    "print(\"\\n\\nðŸŽ‰ All tasks complete â€” Excel + PDF have been downloaded.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
